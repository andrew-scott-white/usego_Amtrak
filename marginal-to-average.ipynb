{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script for adapting marginal grid emissions to average grid emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to make new emissions file with additional Amtrak demand\n",
    "\n",
    "Scale down linearly to eliminate the percentage associated with Amtrak to define a new baseline\n",
    "\n",
    "Difference between base+Amtrak and scaled base+ Amtrak is the avg. attributable to Amtrak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr \n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwriteMarginal = True\n",
    "overwriteAverage = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0         r     t  demandLoad\n",
      "0                0  ERC_REST     1     29087.0\n",
      "1                1  ERC_REST     2     29081.0\n",
      "2                2  ERC_REST     3     29428.0\n",
      "3                3  ERC_REST     4     30073.0\n",
      "4                4  ERC_REST     5     31131.0\n",
      "...            ...       ...   ...         ...\n",
      "534294      534294   WECC_WY  8755      1431.0\n",
      "534295      534295   WECC_WY  8756      1405.0\n",
      "534296      534296   WECC_WY  8757      1355.0\n",
      "534297      534297   WECC_WY  8758      1283.0\n",
      "534298      534298   WECC_WY  8759      1270.0\n",
      "\n",
      "[534299 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "case_name = 'amtk_current'\n",
    "base_load = pd.read_csv('~/us_ego/inputs/inputs_load.csv') # MWh\n",
    "amtk_load = pd.read_csv(f'~/us_ego/inputs/inputs_load_{case_name}.csv') # MWh\n",
    "\n",
    "del_load = amtk_load['demandLoad'] - base_load['demandLoad'] # load attributable to Amtrak\n",
    "\n",
    "mask = del_load > 0\n",
    "del_load = del_load[mask]\n",
    "range_idx = del_load.index\n",
    "print(del_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open existing file; amtrak load + base load grid emissions\n",
    "path='~/us_ego/annual_emissions/'\n",
    "name =f'inventory_power_plants_{case_name}.nc'\n",
    "base_name = f'inventory_power_plants_base.nc'\n",
    "amtrak_grid_emissions = xr.open_dataset(path+name, engine=\"netcdf4\")\n",
    "base_grid_emissions = xr.open_dataset(path+base_name, engine=\"netcdf4\")\n",
    "\n",
    "# Using Dask for large arrays\n",
    "amtrak_grid_chunked = amtrak_grid_emissions.chunk({\"time\": 100})  \n",
    "base_grid_chunked = base_grid_emissions.chunk({\"time\": 100})  \n",
    "\n",
    "amtrak_grid = amtrak_grid_chunked.fillna(0)\n",
    "base_grid = base_grid_chunked.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base NOx emissions: 3291.371893806383 Tg/yr\n"
     ]
    }
   ],
   "source": [
    "print('Base NOx emissions:',(np.sum(base_grid[\"NO\"].values)+np.sum(base_grid[\"NO2\"].values))*3600*123210000/1000/1000,'Tg/yr') # Tg/yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amtrak+base NOx emissions: 3290.2476592585444 Tg/yr\n"
     ]
    }
   ],
   "source": [
    "print('Amtrak+base NOx emissions:',(np.sum(amtrak_grid['NO'].values)+np.sum(amtrak_grid['NO2'].values))*3600*123210000/1000/1000,'Tg/yr') # Tg/yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum fraction of grid load: 0.27 %\n"
     ]
    }
   ],
   "source": [
    "# initialize array of hourly scaling values\n",
    "phi_array = np.zeros(len(range_idx))\n",
    "init_idx = int(range_idx[0])\n",
    "jj = 0\n",
    "\n",
    "for ii in range_idx:\n",
    "    #print(amtk_load['r'][ii],amtk_load['t'][ii],amtk_load['demandLoad'][ii])\n",
    "    phi_array[jj] = del_load[ii]/(amtk_load['demandLoad'][ii])\n",
    "    jj += 1\n",
    "    \n",
    "print('Maximum fraction of grid load:',round(np.max(phi_array)*100, 2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, r, t, demandLoad]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#print(base_load['r'].unique())\n",
    "region='ERC_rest'\n",
    "tt = 5\n",
    "t_low = tt\n",
    "t_high = tt + 2\n",
    "'@t_low < t < @t_high'\n",
    "amtk_load_slice = amtk_load[(amtk_load['t'] < t_high) & (amtk_load['r']==region)]\n",
    "print(amtk_load_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               r  t  demandLoad\n",
      "0       ERC_REST  1       29087\n",
      "8759    ERC_WEST  1        2655\n",
      "17518       FRCC  1       17709\n",
      "26277   MAP_WAUE  1        2551\n",
      "35036     MIS_IA  1        2332\n",
      "...          ... ..         ...\n",
      "490504  WECC_SCE  1       10605\n",
      "499263   WECC_SF  1         542\n",
      "508022  WECC_SNV  1        2196\n",
      "516781   WECC_UT  1        4050\n",
      "525540   WECC_WY  1        1356\n",
      "\n",
      "[61 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "t = 1\n",
    "t_high = t + 1\n",
    "t_low = t - 1\n",
    "\n",
    "dat1 = base_load.query('@t_low < t < @t_high')\n",
    "print(dat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open existing file; amtrak load + base load grid emissions\n",
    "path='~/us_ego/annual_emissions/'\n",
    "name =f'inventory_power_plants_{case_name}.nc'\n",
    "base_name = f'inventory_power_plants_base.nc'\n",
    "amtrak_grid_emissions = xr.open_dataset(path+name, engine=\"netcdf4\")\n",
    "base_grid_emissions = xr.open_dataset(path+base_name, engine=\"netcdf4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-01 00:00:00\n",
      "1:00:00\n",
      "2016-01-01 01:00:00\n"
     ]
    }
   ],
   "source": [
    "#print(amtrak_grid_emissions)\n",
    "from datetime import datetime, timedelta\n",
    "time = datetime(2016,1,1,0,0,0)\n",
    "print(time)\n",
    "dt = timedelta(hours=1)\n",
    "print(dt)\n",
    "print(time + dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#species_list = [i for i in amtrak_grid_emissions.data_vars] \n",
    "#print(species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 38GB\n",
      "Dimensions:  (time: 8760, lat: 400, lon: 900)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 70kB 2016-01-01 ... 2016-12-30T23:00:00\n",
      "  * lat      (lat) float64 3kB 20.05 20.15 20.25 20.35 ... 59.75 59.85 59.95\n",
      "  * lon      (lon) float64 7kB -139.9 -139.8 -139.8 ... -50.25 -50.15 -50.05\n",
      "Data variables:\n",
      "    NO       (time, lat, lon) float32 13GB dask.array<chunksize=(100, 400, 900), meta=np.ndarray>\n",
      "    NO2      (time, lat, lon) float32 13GB dask.array<chunksize=(100, 400, 900), meta=np.ndarray>\n",
      "    SO2      (time, lat, lon) float32 13GB dask.array<chunksize=(100, 400, 900), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Title:        Hourly CH power plant inventory\n",
      "    Conventions:  COARDS\n",
      "    History:      Created 2025-04-26\n",
      "    Contact:      aswhite@mit.edu\n"
     ]
    }
   ],
   "source": [
    "# Using Dask for large arrays\n",
    "amtrak_grid = amtrak_grid_emissions.chunk({\"time\": 100})  \n",
    "base_grid = base_grid_emissions.chunk({\"time\": 100})  \n",
    "\n",
    "print(amtrak_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if overwriteMarginal == True:\n",
    "    # Marginal Amtrak emissions: calculate difference between amtk_grid and base_grid\n",
    "    marginal_diff_grid = xr.ufuncs.subtract(amtrak_grid, base_grid) # ufuncs automatically uses dask chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 76GB\n",
      "Dimensions:  (time: 8760, lat: 400, lon: 900)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 70kB 2016-01-01 ... 2016-12-30T23:00:00\n",
      "  * lat      (lat) float64 3kB 20.05 20.15 20.25 20.35 ... 59.75 59.85 59.95\n",
      "  * lon      (lon) float64 7kB -139.9 -139.8 -139.8 ... -50.25 -50.15 -50.05\n",
      "Data variables:\n",
      "    NO       (time, lat, lon) float64 25GB dask.array<chunksize=(100, 400, 900), meta=np.ndarray>\n",
      "    NO2      (time, lat, lon) float64 25GB dask.array<chunksize=(100, 400, 900), meta=np.ndarray>\n",
      "    SO2      (time, lat, lon) float64 25GB dask.array<chunksize=(100, 400, 900), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "if overwriteMarginal == True:\n",
    "    print(marginal_diff_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if overwriteMarginal == True:\n",
    "    # save to Dataset to path\n",
    "    path='~/fs11/amtrak_emissions'\n",
    "    name = (f'inventory_power_plants_{case_name}_marginal.nc')\n",
    "    marginal_diff_grid.to_netcdf(path+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 76GB\n",
      "Dimensions:  (time: 8760, lat: 400, lon: 900)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 70kB 2016-01-01 ... 2016-12-30T23:00:00\n",
      "  * lat      (lat) float64 3kB 20.05 20.15 20.25 20.35 ... 59.75 59.85 59.95\n",
      "  * lon      (lon) float64 7kB -139.9 -139.8 -139.8 ... -50.25 -50.15 -50.05\n",
      "Data variables:\n",
      "    NO       (time, lat, lon) float64 25GB dask.array<chunksize=(100, 400, 900), meta=np.ndarray>\n",
      "    NO2      (time, lat, lon) float64 25GB dask.array<chunksize=(100, 400, 900), meta=np.ndarray>\n",
      "    SO2      (time, lat, lon) float64 25GB dask.array<chunksize=(100, 400, 900), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "print(marginal_diff_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open existing file; amtrak load + base load grid emissions\n",
    "path='~/fs11/amtrak_emissions/'\n",
    "name_1 = (f'inventory_power_plants_{case_name}_marginal.nc')\n",
    "name_2 = (f'inventory_power_plants_{case_name}_average.nc')\n",
    "marginal_diff_grid = xr.open_dataset(path+name_1, engine=\"netcdf4\")\n",
    "average_diff_grid = xr.open_dataset(path+name_2, engine=\"netcdf4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 23.5 GiB for an array with shape (8760, 400, 900) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m marginal_diff_grid \u001b[38;5;241m=\u001b[39m marginal_diff_grid\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# kg/m2/s\u001b[39;00m\n\u001b[1;32m      2\u001b[0m average_diff_grid \u001b[38;5;241m=\u001b[39m average_diff_grid\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/dataset.py:6705\u001b[0m, in \u001b[0;36mDataset.fillna\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   6700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(value_keys) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_vars\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m   6701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   6702\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall variables in the argument to `fillna` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6703\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be contained in the original dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6704\u001b[0m         )\n\u001b[0;32m-> 6705\u001b[0m out \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;28mself\u001b[39m, value)\n\u001b[1;32m   6706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/ops.py:148\u001b[0m, in \u001b[0;36mfillna\u001b[0;34m(data, other, join, dataset_join)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fill missing values in this object with data from the other object.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mFollows normal broadcasting and alignment rules.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    - \"right\": take only variables from the last object\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_ufunc\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m apply_ufunc(\n\u001b[1;32m    149\u001b[0m     duck_array_ops\u001b[38;5;241m.\u001b[39mfillna,\n\u001b[1;32m    150\u001b[0m     data,\n\u001b[1;32m    151\u001b[0m     other,\n\u001b[1;32m    152\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m    153\u001b[0m     dask\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallowed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    154\u001b[0m     dataset_join\u001b[38;5;241m=\u001b[39mdataset_join,\n\u001b[1;32m    155\u001b[0m     dataset_fill_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan,\n\u001b[1;32m    156\u001b[0m     keep_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    157\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/computation.py:1258\u001b[0m, in \u001b[0;36mapply_ufunc\u001b[0;34m(func, input_core_dims, output_core_dims, exclude_dims, vectorize, join, dataset_join, dataset_fill_value, keep_attrs, kwargs, dask, output_dtypes, output_sizes, meta, dask_gufunc_kwargs, on_missing_core_dim, *args)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;66;03m# feed datasets apply_variable_ufunc through apply_dataset_vfunc\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_dict_like(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m-> 1258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_dataset_vfunc(\n\u001b[1;32m   1259\u001b[0m         variables_vfunc,\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m   1261\u001b[0m         signature\u001b[38;5;241m=\u001b[39msignature,\n\u001b[1;32m   1262\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m   1263\u001b[0m         exclude_dims\u001b[38;5;241m=\u001b[39mexclude_dims,\n\u001b[1;32m   1264\u001b[0m         dataset_join\u001b[38;5;241m=\u001b[39mdataset_join,\n\u001b[1;32m   1265\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mdataset_fill_value,\n\u001b[1;32m   1266\u001b[0m         keep_attrs\u001b[38;5;241m=\u001b[39mkeep_attrs,\n\u001b[1;32m   1267\u001b[0m         on_missing_core_dim\u001b[38;5;241m=\u001b[39mon_missing_core_dim,\n\u001b[1;32m   1268\u001b[0m     )\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;66;03m# feed DataArray apply_variable_ufunc through apply_dataarray_vfunc\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, DataArray) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/computation.py:529\u001b[0m, in \u001b[0;36mapply_dataset_vfunc\u001b[0;34m(func, signature, join, dataset_join, fill_value, exclude_dims, keep_attrs, on_missing_core_dim, *args)\u001b[0m\n\u001b[1;32m    524\u001b[0m list_of_coords, list_of_indexes \u001b[38;5;241m=\u001b[39m build_output_coords_and_indexes(\n\u001b[1;32m    525\u001b[0m     args, signature, exclude_dims, combine_attrs\u001b[38;5;241m=\u001b[39mkeep_attrs\n\u001b[1;32m    526\u001b[0m )\n\u001b[1;32m    527\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_vars\u001b[39m\u001b[38;5;124m\"\u001b[39m, arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[0;32m--> 529\u001b[0m result_vars \u001b[38;5;241m=\u001b[39m apply_dict_of_variables_vfunc(\n\u001b[1;32m    530\u001b[0m     func,\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    532\u001b[0m     signature\u001b[38;5;241m=\u001b[39msignature,\n\u001b[1;32m    533\u001b[0m     join\u001b[38;5;241m=\u001b[39mdataset_join,\n\u001b[1;32m    534\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    535\u001b[0m     on_missing_core_dim\u001b[38;5;241m=\u001b[39mon_missing_core_dim,\n\u001b[1;32m    536\u001b[0m )\n\u001b[1;32m    538\u001b[0m out: Dataset \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Dataset, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/computation.py:453\u001b[0m, in \u001b[0;36mapply_dict_of_variables_vfunc\u001b[0;34m(func, signature, join, fill_value, on_missing_core_dim, *args)\u001b[0m\n\u001b[1;32m    451\u001b[0m core_dim_present \u001b[38;5;241m=\u001b[39m _check_core_dims(signature, variable_args, name)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m core_dim_present \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 453\u001b[0m     result_vars[name] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39mvariable_args)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on_missing_core_dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/computation.py:735\u001b[0m, in \u001b[0;36mapply_variable_ufunc\u001b[0;34m(func, signature, exclude_dims, dask, output_dtypes, vectorize, keep_attrs, dask_gufunc_kwargs, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m broadcast_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    729\u001b[0m     dim \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m dim_sizes \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mall_core_dims\n\u001b[1;32m    730\u001b[0m )\n\u001b[1;32m    731\u001b[0m output_dims \u001b[38;5;241m=\u001b[39m [broadcast_dims \u001b[38;5;241m+\u001b[39m out \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m signature\u001b[38;5;241m.\u001b[39moutput_core_dims]\n\u001b[1;32m    733\u001b[0m input_data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    734\u001b[0m     (\n\u001b[0;32m--> 735\u001b[0m         broadcast_compat_data(arg, broadcast_dims, core_dims)\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Variable)\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[1;32m    738\u001b[0m     )\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg, core_dims \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, signature\u001b[38;5;241m.\u001b[39minput_core_dims, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    740\u001b[0m ]\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_chunked_array(array) \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m input_data):\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforbidden\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/computation.py:656\u001b[0m, in \u001b[0;36mbroadcast_compat_data\u001b[0;34m(variable, broadcast_dims, core_dims)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_compat_data\u001b[39m(\n\u001b[1;32m    652\u001b[0m     variable: Variable,\n\u001b[1;32m    653\u001b[0m     broadcast_dims: \u001b[38;5;28mtuple\u001b[39m[Hashable, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m    654\u001b[0m     core_dims: \u001b[38;5;28mtuple\u001b[39m[Hashable, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m    655\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 656\u001b[0m     data \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    658\u001b[0m     old_dims \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mdims\n\u001b[1;32m    659\u001b[0m     new_dims \u001b[38;5;241m=\u001b[39m broadcast_dims \u001b[38;5;241m+\u001b[39m core_dims\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/variable.py:415\u001b[0m, in \u001b[0;36mVariable.data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, indexing\u001b[38;5;241m.\u001b[39mExplicitlyIndexed):\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mget_duck_array()\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/indexing.py:835\u001b[0m, in \u001b[0;36mMemoryCachedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 835\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_cached()\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/indexing.py:832\u001b[0m, in \u001b[0;36mMemoryCachedArray._ensure_cached\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_cached\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m as_indexable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array())\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/indexing.py:789\u001b[0m, in \u001b[0;36mCopyOnWriteArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/indexing.py:652\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    648\u001b[0m     array \u001b[38;5;241m=\u001b[39m apply_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# If the array is not an ExplicitlyIndexedNDArrayMixin,\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;66;03m# it may wrap a BackendArray so use its __getitem__\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey]\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:103\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indexing\u001b[38;5;241m.\u001b[39mexplicit_indexing_adapter(\n\u001b[1;32m    104\u001b[0m         key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, indexing\u001b[38;5;241m.\u001b[39mIndexingSupport\u001b[38;5;241m.\u001b[39mOUTER, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem\n\u001b[1;32m    105\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/indexing.py:1013\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Support explicit indexing by delegating to a raw indexing method.\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \n\u001b[1;32m    993\u001b[0m \u001b[38;5;124;03mOuter and/or vectorized indexers are supported by indexing a second time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;124;03mIndexing result, in the form of a duck numpy-array.\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[0;32m-> 1013\u001b[0m result \u001b[38;5;241m=\u001b[39m raw_indexing_method(raw_key\u001b[38;5;241m.\u001b[39mtuple)\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;66;03m# index the loaded np.ndarray\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m     indexable \u001b[38;5;241m=\u001b[39m NumpyIndexingAdapter(result)\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:116\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    115\u001b[0m         original_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_array(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 116\u001b[0m         array \u001b[38;5;241m=\u001b[39m getitem(original_array, key)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# Catch IndexError in netCDF4 and return a more informative\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# error message.  This is most often called when an unsorted\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# indexer is used before the data is loaded from disk.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe indexing operation you are attempting to perform \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not valid on netCDF4.Variable object. Try loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data into memory first by calling .load().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m     )\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:5060\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 23.5 GiB for an array with shape (8760, 400, 900) and data type float64"
     ]
    }
   ],
   "source": [
    "marginal_diff_grid = marginal_diff_grid.fillna(0) # kg/m2/s\n",
    "average_diff_grid = average_diff_grid.fillna(0) # kg/m2/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 23.5 GiB for an array with shape (8760, 400, 900) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnnual grid average NOx emissions from Amtrak:\u001b[39m\u001b[38;5;124m'\u001b[39m,(np\u001b[38;5;241m.\u001b[39msum(marginal_diff_grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNO\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m+\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(marginal_diff_grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNO2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3600\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m123210000\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMg/yr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Mg/yr\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnnual grid average NOx emissions from Amtrak:\u001b[39m\u001b[38;5;124m'\u001b[39m,(np\u001b[38;5;241m.\u001b[39msum(average_diff_grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNO\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m+\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(average_diff_grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNO2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3600\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m123210000\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMg/yr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/dataarray.py:814\u001b[0m, in \u001b[0;36mDataArray.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m    The array's data converted to numpy.ndarray.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m    to this array may be reflected in the DataArray as well.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/variable.py:507\u001b[0m, in \u001b[0;36mVariable.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    506\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _as_array_or_item(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/variable.py:301\u001b[0m, in \u001b[0;36m_as_array_or_item\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_array_or_item\u001b[39m(data):\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    303\u001b[0m         kind \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/indexing.py:511\u001b[0m, in \u001b[0;36mExplicitlyIndexed.__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_duck_array(), dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_duck_array(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/indexing.py:835\u001b[0m, in \u001b[0;36mMemoryCachedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 835\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_cached()\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/indexing.py:832\u001b[0m, in \u001b[0;36mMemoryCachedArray._ensure_cached\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_cached\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m as_indexable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array())\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/indexing.py:789\u001b[0m, in \u001b[0;36mCopyOnWriteArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/indexing.py:652\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    648\u001b[0m     array \u001b[38;5;241m=\u001b[39m apply_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# If the array is not an ExplicitlyIndexedNDArrayMixin,\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;66;03m# it may wrap a BackendArray so use its __getitem__\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey]\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:103\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indexing\u001b[38;5;241m.\u001b[39mexplicit_indexing_adapter(\n\u001b[1;32m    104\u001b[0m         key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, indexing\u001b[38;5;241m.\u001b[39mIndexingSupport\u001b[38;5;241m.\u001b[39mOUTER, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem\n\u001b[1;32m    105\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/core/indexing.py:1013\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Support explicit indexing by delegating to a raw indexing method.\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \n\u001b[1;32m    993\u001b[0m \u001b[38;5;124;03mOuter and/or vectorized indexers are supported by indexing a second time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;124;03mIndexing result, in the form of a duck numpy-array.\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[0;32m-> 1013\u001b[0m result \u001b[38;5;241m=\u001b[39m raw_indexing_method(raw_key\u001b[38;5;241m.\u001b[39mtuple)\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;66;03m# index the loaded np.ndarray\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m     indexable \u001b[38;5;241m=\u001b[39m NumpyIndexingAdapter(result)\n",
      "File \u001b[0;32m~/.conda/envs/emis_map/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:116\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    115\u001b[0m         original_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_array(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 116\u001b[0m         array \u001b[38;5;241m=\u001b[39m getitem(original_array, key)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# Catch IndexError in netCDF4 and return a more informative\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# error message.  This is most often called when an unsorted\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# indexer is used before the data is loaded from disk.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe indexing operation you are attempting to perform \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not valid on netCDF4.Variable object. Try loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data into memory first by calling .load().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m     )\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:5060\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 23.5 GiB for an array with shape (8760, 400, 900) and data type float64"
     ]
    }
   ],
   "source": [
    "print('Annual grid average NOx emissions from Amtrak:',(np.sum(marginal_diff_grid[\"NO\"].values)+np.sum(marginal_diff_grid[\"NO2\"].values))*3600*123210000/1000,'Mg/yr') # Mg/yr\n",
    "print('Annual grid average NOx emissions from Amtrak:',(np.sum(average_diff_grid[\"NO\"].values)+np.sum(average_diff_grid[\"NO2\"].values))*3600*123210000/1000,'Mg/yr') # Mg/yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emis_map",
   "language": "python",
   "name": "emis_map"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
